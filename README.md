The project is My Final Project issued from McMaster Universities Computing and Software Department. <br />
Dr. YingYing Wang from the Computing and Software department is being the supervisor of my project and the project was handled fully by me.<br />
The project works using ACR https://semanticdh.github.io/ACR/ and Mano https://mano.is.tue.mpg.de/ and the videos were taken from this pre-trained Sign language dataset https://how2sign.github.io/ <br />
Instructions to install and work- <br />
(works over python 3.8.8) <br />
`pip install python==3.8.8` <br />
`pip install torch==1.10.1+cpu torchvision==0.11.2+cpu torchaudio==0.10.1 -f https://download.pytorch.org/whl/cpu/torch_stable.html` <br />
`pip install -r requirements.txt` <br />
`pip install mediapipe` <br />

then run <br />
`python main.py` <br />

This provides the result by taking the input of a video and providing an output of the 3d hands. <br />
The project report follows the MacSphere Project reports from here https://macsphere.mcmaster.ca/handle/11375/27/simple-search?filterquery=Computing+and+Software&filtername=department&filtertype=equals . <br />
The project demos are provided in the demos folder.

The use of rights is reserved by @XessX.
